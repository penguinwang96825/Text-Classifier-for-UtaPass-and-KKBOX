{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.common import flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\YangWang\\Desktop\\Text_Classifier_for_UtaPass_and_KKBOX\\data\\utapass_and_kkbox_total_reviews_20200422.csv\")\n",
    "df = df[[\"content\", \"rating\"]]\n",
    "df.columns = [\"content\", \"label\"]\n",
    "df[\"content\"] = df[\"content\"].apply(str)\n",
    "df[\"label\"] = df[\"label\"].apply(int)\n",
    "df[\"label\"] = df[\"label\"].map(lambda x: 1 if int(x)>3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>いちいちアプリを立ち上げてライブラリから曲を選択して再生…。 非常に不便です。 時間がたって...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>他の携帯繋げても無料で聴けるのはいい。でも月額払って仮に間違えて違う曲を保存した時に削除する...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>初めて使ったが、どんなアーティストがいるか、わからないので、アーティスト別検索見てたら、全ア...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ログインボタンを押すと「不明なエラー」と表示されます…不明なエラーとはいったい？長年auユー...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>音質もいいしBluetoothにつないで車の中で聴くのがお気に入りです。 毎日更新されるのも...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>最低</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>パーフェクト</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>最高</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>最高だよ🎵(^-^)  このアプリ😃</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label\n",
       "0     いちいちアプリを立ち上げてライブラリから曲を選択して再生…。 非常に不便です。 時間がたって...      0\n",
       "1     他の携帯繋げても無料で聴けるのはいい。でも月額払って仮に間違えて違う曲を保存した時に削除する...      0\n",
       "2     初めて使ったが、どんなアーティストがいるか、わからないので、アーティスト別検索見てたら、全ア...      0\n",
       "3     ログインボタンを押すと「不明なエラー」と表示されます…不明なエラーとはいったい？長年auユー...      0\n",
       "4     音質もいいしBluetoothにつないで車の中で聴くのがお気に入りです。 毎日更新されるのも...      1\n",
       "...                                                 ...    ...\n",
       "3494                                                 最低      0\n",
       "3495                                             パーフェクト      1\n",
       "3496                                               Good      0\n",
       "3497                                                 最高      1\n",
       "3498                                 最高だよ🎵(^-^)  このアプリ😃      1\n",
       "\n",
       "[3499 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative %   # Words  # Comments\n",
      " 80.28008   \t  61 \t    19\n",
      " 85.11003   \t  74 \t    12\n",
      " 90.19720   \t  93 \t    8\n",
      " 92.11203   \t  103 \t    10\n",
      " 95.05573   \t  127 \t    2\n"
     ]
    }
   ],
   "source": [
    "df[\"length\"] = df[\"content\"].map(len)\n",
    "text_len = df[\"length\"].values\n",
    "max_len = text_len.max()\n",
    "\n",
    "len_sum = [0] * max_len\n",
    "for i in text_len:\n",
    "    len_sum[i-1] += 1\n",
    "    \n",
    "len_cum = [len_sum[0]] + [0] * (max_len-1)\n",
    "for i in range(1, max_len):\n",
    "    len_cum[i] += len_sum[i] + len_cum[i-1]\n",
    "\n",
    "print('Cumulative %   # Words  # Comments')\n",
    "for i in range(max_len):\n",
    "    len_cum[i] /= len(text_len)\n",
    "    if len_sum[i] != 0:\n",
    "        if (len_cum[i] >= 0.8 and len_cum[i-1] < 0.8):\n",
    "            print(' %.5f   \\t  %d \\t    %d'%(len_cum[i]*100, i, len_sum[i]))\n",
    "        if (len_cum[i] >= 0.85 and len_cum[i-1] < 0.85):\n",
    "            print(' %.5f   \\t  %d \\t    %d'%(len_cum[i]*100, i, len_sum[i]))\n",
    "        if (len_cum[i] >= 0.9 and len_cum[i-1] < 0.9):\n",
    "            print(' %.5f   \\t  %d \\t    %d'%(len_cum[i]*100, i, len_sum[i]))\n",
    "        if (len_cum[i] >= 0.92 and len_cum[i-1] < 0.92):\n",
    "            print(' %.5f   \\t  %d \\t    %d'%(len_cum[i]*100, i, len_sum[i]))\n",
    "        if (len_cum[i] >= 0.95 and len_cum[i-1] < 0.95):\n",
    "            print(' %.5f   \\t  %d \\t    %d'%(len_cum[i]*100, i, len_sum[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9c6349860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"length\"].plot(kind=\"hist\", \n",
    "                  title=\"Sentence Length Distribution\", \n",
    "                  range=(0, 100), \n",
    "                  figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"length\"] >= 10]\n",
    "train, test = train_test_split(df, train_size=0.9, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mecab_list(text):\n",
    "    pos_list = [10, 11, 31, 32, 34]\n",
    "    pos_list.extend(list(range(36,50)))\n",
    "    pos_list.extend([59, 60, 62, 67])\n",
    "\n",
    "    mecab_list = []\n",
    "    mecab = MeCab.Tagger(\"-Ochasen\")\n",
    "    mecab.parse(\"\")\n",
    "    # encoding = text.encode('utf-8')\n",
    "    node = mecab.parseToNode(text)\n",
    "    while node:\n",
    "        if len(node.surface) > 1:\n",
    "            if node.posid in pos_list:\n",
    "                morpheme = node.surface\n",
    "                mecab_list.append(morpheme)\n",
    "        node = node.next\n",
    "    return mecab_list\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = pd.read_csv(\"C:/Users/YangWang/Desktop/Text_Classifier_for_UtaPass_and_KKBOX/Japanese_stopword_list.txt\", \n",
    "                    encoding=\"utf-8\", header=None, sep=\"\\n\")\n",
    "    stopwords = list(flatten(stopwords.values.tolist()))\n",
    "    filtered_words = [word for word in text if word not in stopwords]\n",
    "    return \"\".join(filtered_words)\n",
    "\n",
    "def give_emoji_free_text(text):\n",
    "    allchars = [string for string in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    cleaned_text = ''.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return cleaned_text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = remove_stopwords(text)\n",
    "    text = give_emoji_free_text(text)\n",
    "    text = create_mecab_list(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        print(\"Loading word vectors...\")\n",
    "        self.w2v = Word2Vec.load(r\"C:\\Users\\YangWang\\Desktop\\Text_Classifier_for_UtaPass_and_KKBOX\\word2vec\\ja.bin\")\n",
    "        print(\"Finished loading in word vectors.\")\n",
    "        \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        v = self.w2v.wv.get_vector(\"の\")\n",
    "        self.D = v.shape[0]\n",
    "        \n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = create_mecab_list(sentence)\n",
    "            vecs = []\n",
    "            m = 0\n",
    "            for word in tokens:\n",
    "                try: \n",
    "                    vec = self.w2v.wv.get_vector(word)\n",
    "                    vecs.append(vec)\n",
    "                    m += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Number of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Finished loading in word vectors.\n",
      "Number of samples with no words found: 329 / 2467\n",
      "Number of samples with no words found: 31 / 275\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Word2VecVectorizer()\n",
    "x_train = vectorizer.fit_transform(train.content)\n",
    "y_train = train.label\n",
    "\n",
    "x_test = vectorizer.fit_transform(test.content)\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data: 2467\n",
      "# of features: 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.57018113, -0.26452327,  1.21205962, ...,  0.39846775,\n",
       "        -0.00379243,  0.55407727],\n",
       "       [-0.85002381,  0.33833307,  0.60584986, ...,  0.02884466,\n",
       "         0.31363925, -0.54602474],\n",
       "       [-0.27264288,  0.37544754,  0.16551086, ..., -0.02856954,\n",
       "        -0.25689915, -0.33307162],\n",
       "       ...,\n",
       "       [-1.27766061, -0.12002245,  0.39763317, ...,  2.00929737,\n",
       "        -0.41422769, -1.4116869 ],\n",
       "       [-0.44685814,  0.19290257,  0.66804117, ...,  0.57713288,\n",
       "         0.41261983,  0.3783901 ],\n",
       "       [-0.79977345, -0.03050352, -0.03237534, ...,  1.67542517,\n",
       "        -0.34743407, -1.31029689]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"# of training data: {}\\n# of features: {}\".format(x_train.shape[0], x_train.shape[1]))\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(model, x_train, y_train, x_test, y_test):\n",
    "    print(\"train score: \", round(model.score(x_train, y_train), 4))\n",
    "    print(\"test score: \", round(model.score(x_test, y_test), 4))\n",
    "    print(\"f-beta score: \", round(f1_score(y_test, model.predict(x_test)), 4))\n",
    "    print(\"roc auc score: \", round(roc_auc_score(y_test, model.predict(x_test)), 4))\n",
    "    print(\"confusion matrix: \\n\", confusion_matrix(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9039\n",
      "test score:  0.6945\n",
      "f-beta score:  0.6\n",
      "roc auc score:  0.6745\n",
      "confusion matrix: \n",
      " [[128  38]\n",
      " [ 46  63]]\n"
     ]
    }
   ],
   "source": [
    "rfc_model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    random_state=17)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "performance(rfc_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.7106\n",
      "test score:  0.6545\n",
      "f-beta score:  0.4099\n",
      "roc auc score:  0.5941\n",
      "confusion matrix: \n",
      " [[147  19]\n",
      " [ 76  33]]\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=10)\n",
    "knn_model.fit(x_train, y_train)\n",
    "performance(knn_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9047\n",
      "test score:  0.6873\n",
      "f-beta score:  0.5981\n",
      "roc auc score:  0.6701\n",
      "confusion matrix: \n",
      " [[125  41]\n",
      " [ 45  64]]\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    learning_rate=0.01, \n",
    "    n_estimators=500, \n",
    "    max_depth=10, \n",
    "    min_child_weight = 1, \n",
    "    gamma=0., \n",
    "    subsample=1, \n",
    "    colsample_btree=1, \n",
    "    scale_pos_weight=1, \n",
    "    random_state=17, \n",
    "    slient = 0)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "performance(xgb_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9661\n",
      "test score:  0.767\n",
      "f-beta score:  0.6111\n",
      "roc auc score:  0.6793\n",
      "confusion matrix: \n",
      " [[125  41]\n",
      " [ 43  66]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.02,  \n",
    "    random_state=17, \n",
    "    slient = 0)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [400, 500, 600], \n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=17)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, \n",
    "    param_distributions=params, \n",
    "    n_iter=param_comb, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=4, \n",
    "    cv=skf.split(x_train, y_train), \n",
    "    verbose=2, \n",
    "    random_state=17)\n",
    "random_search.fit(x_train, y_train)\n",
    "performance(random_search, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=2,\n",
      "              learning_rate=0.02, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=5, missing=None, n_estimators=400, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=17,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, slient=0, subsample=0.8, verbosity=1)\n",
      "\n",
      " Best hyperparameters: \n",
      "\n",
      "{'subsample': 0.8, 'n_estimators': 400, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('Best estimator: \\n')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best hyperparameters: \\n')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9661\n",
      "test score:  0.767\n",
      "f-beta score:  0.6111\n",
      "roc auc score:  0.6793\n",
      "confusion matrix: \n",
      " [[125  41]\n",
      " [ 43  66]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.02, \n",
    "    n_estimators=2000, \n",
    "    random_state=17, \n",
    "    slient = 0)\n",
    "\n",
    "params = {\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [5, 10, 15, 20]\n",
    "}\n",
    "gsearch = GridSearchCV(\n",
    "    xgb, \n",
    "    param_grid=params, \n",
    "    scoring='f1', \n",
    "    cv=3, \n",
    "    n_jobs=4)\n",
    "gsearch.fit(x_train, y_train)\n",
    "performance(random_search, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=1,\n",
      "              learning_rate=0.02, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=10, missing=None, n_estimators=2000, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=17,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, slient=0, subsample=0.6, verbosity=1)\n",
      "\n",
      " Best hyperparameters: \n",
      "\n",
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.8, 'gamma': 1, 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 10, 'missing': None, 'n_estimators': 2000, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 17, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 0.6, 'verbosity': 1, 'slient': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Best estimator: \\n')\n",
    "print(gsearch.best_estimator_)\n",
    "print('\\n Best hyperparameters: \\n')\n",
    "print(gsearch.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9039\n",
      "test score:  0.7127\n",
      "f-beta score:  0.607\n",
      "roc auc score:  0.6864\n",
      "confusion matrix: \n",
      " [[135  31]\n",
      " [ 48  61]]\n"
     ]
    }
   ],
   "source": [
    "etc_model = ExtraTreesClassifier(\n",
    "    n_estimators=200,\n",
    "    criterion='gini', \n",
    "    random_state=17)\n",
    "etc_model.fit(x_train, y_train)\n",
    "performance(etc_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.7369\n",
      "test score:  0.6509\n",
      "f-beta score:  0.5826\n",
      "roc auc score:  0.6447\n",
      "confusion matrix: \n",
      " [[112  54]\n",
      " [ 42  67]]\n"
     ]
    }
   ],
   "source": [
    "dtc_model = DecisionTreeClassifier(\n",
    "    max_depth=5, \n",
    "    criterion='gini', \n",
    "    random_state=17)\n",
    "dtc_model.fit(x_train, y_train)\n",
    "performance(dtc_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9043\n",
      "test score:  0.6982\n",
      "f-beta score:  0.5951\n",
      "roc auc score:  0.6744\n",
      "confusion matrix: \n",
      " [[131  35]\n",
      " [ 48  61]]\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(\n",
    "    estimators=[('rfc', rfc_model), ('xgb', xgb_model), ('etc', etc_model), ('dtc', dtc_model)],\n",
    "    voting='soft')\n",
    "eclf.fit(x_train, y_train)\n",
    "performance(eclf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
